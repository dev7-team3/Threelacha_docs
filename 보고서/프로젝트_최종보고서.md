# 농수산물 대시보드 최종 프로젝트 보고서
<div align="right"> 📅 2026-01-06 </div>

# 1. 프로젝트 개요

## 1.1 프로젝트 주제

> 농축수산물 공공데이터를 수집·분석·시각화하여, 
소비자의 합리적인 구매 의사결정 돕는 대시보드 구축 프로젝트
> 

## 1.2 프로젝트 배경

- **고물가 및 가격 변동성 심화
:** 외식비 상승으로 집밥 수요는 늘었으나, 농축수산물의 심한 가격 급등락으로 인해 소비자의 장바구니 부담이 지속됨.
- **데이터 파편화 및 정보 비대칭성
:** 가격 정보가 유통 채널별로 산발적으로 제공되고, 특히 친환경 농산물은 정보 접근성이 낮아 종합적인 비교 분석이 어려움.
- **의사결정 지원 시스템 부재
:** 전통시장, 대형마트 등 다양한 유통 채널 간의 가격 정보를 통합적으로 비교·분석할 수 있는 기능의 부재로 인해, 최적의 구매 시점과 장소를 판단하기 위한 소비자의 탐색 비용이 과다 발생함.

## 1.3 프로젝트 목표

- **ETL/ELT 로직 설계 및 로컬 검증**
    - 공공 API 기반 농수산물 데이터 수집을 위한 ETL(Extract-Transform-Load) 및 ELT 로직을 구현하고, 클라우드 이관 전 로컬 환경에서 데이터 정합성 및 파이프라인 안정성을 사전 점검함.
- **AWS 기반 데이터 파이프라인 자동화**
    - 로컬에서 검증된 로직을 AWS 클라우드로 이관하여, 반복적인 데이터 수집 및 가공 프로세스를 무중단으로 수행하는 자동화 배치 환경을 구축함.
- **Streamlit 기반 통합 가격정보 대시보드 구현**
    - 파이프라인을 통해 정제된 데이터를 사용자 중심의 인터페이스로 시각화하여, 물가 변동 확인 및 합리적 구매 의사결정을 돕는 분석 도구를 제공함.

# 2. 프로젝트 진행

## 2.1 기술스택

- **데이터 파이프라인 및 인프라**

    <img width="942" height="459" alt="기술스택_이미지" src="https://github.com/user-attachments/assets/aed0ff5c-51c5-4651-a615-c16109990d22" />
    
    | **구분** | **기술 스택** | **역할 및 활용** |
    | --- | --- | --- |
    | **언어** | **Python** | 데이터 수집, ETL/ELT 로직 구현 및 데이터 가공 |
    | **컨테이너** | **Docker Compose** | 파이프라인 구성 요소의 표준화 및 로컬/클라우드 환경의 일관성 유지 |
    | **워크플로우** | **Apache Airflow** | 데이터 수집 및 배치 파이프라인의 오케스트레이션 및 스케줄링 관리 |
    | **데이터 모델링** | **dbt** | 분석용 데이터 마트 구성을 위한 SQL 기반 데이터 모델링 |
    | **쿼리 엔진** | **Trino / Amazon Athena** | dbt 구동 및 대시보드 연동을 위한 분산 분석 쿼리 엔진 |
    | **메타데이터** | **Hive Metastore / AWS Glue** | 데이터 테이블 스키마 및 파티션 정보 관리 (서버리스 메타스토어 활용) |
    | **스토리지** | **MinIO / Amazon S3** | Raw / Silver / Gold 데이터의 단계별 저장소 (로컬: MinIO, AWS: S3) |
    | **메타/프로덕션 DB** | **PostgreSQL / Amazon RDS** | Airflow 메타데이터 저장 및 Gold Layer 데이터 서빙 DB |
    | **CI/CD** | **Github Actions** | 코드 변경 시 자동화된 테스트 및 AWS 환경으로의 지속적 배포(CD) 수행 |
    | **모니터링** | **AWS CloudWatch** | 인프라 자원 사용량 모니터링 및 메일 통한 알림 시스템 구축 |
    | **자동화 운영** | **AWS Lambda** | 인프라 비용 절감을 위한 스케줄링 기반 인스턴 (EC2/RDS) 자동 기동/정지 관리 |
- **분석 및 시각화**
    
    
    | **구분** | **기술 스택** | **역할 및 활용** |
    | --- | --- | --- |
    | **분석/검증** | **Jupyter Notebook / Spark** | 데이터 탐색(EDA) 및 ETL 로직 사전 검증 |
    | **시각화** | **Streamlit** | 통합 정보 대시보드 서비스 구현 |

## 2.2 시스템 아키텍쳐

### **2.2.1 로컬 및 개발 환경**

<img width="1273" height="701" alt="local_pipeline" src="https://github.com/user-attachments/assets/49546ea5-34c7-4534-9b02-79b71d5c3f47" />

> **💡 AWS 아키텍쳐와 유사한 로컬환경을 사전에 구성한 배경은?**
>
> - **아키텍처 이해도 제고 및 기술 검증** (**인프라/구조적 관점**)<br>
>   Glue Catalog와 Athena 등 생소한 AWS 서비스 도입에 앞서 로컬에 유사 환경을 선제적으로 구축함으로써, 전체 아키텍처의 데이터 흐름을 명확히 이해하고 설계 오류를 사전에 식별·완화하기 위함.
> - **단계별 프로토타입 구현을 통한 로직 가시화** (**데이터/로직 관점**)<br>
>   데이터 수집부터 마트 생성까지의 전 과정을 로컬에서 프로토타입으로 간략히 구현하여, 실제 가동 전 비즈니스 로직의 타당성을 검토하고 파이프라인의 핵심 기능을 조기에 확정하기 위함.
> - **운영 지속성 및 복구 가용성 마련** (**운영·유지보수 관점**)<br>
>   프로젝트 종료 후의 자원 정리 상황에 대비하여 언제든 재구축이 가능한 'Portable' 개발 환경을 조성함으로써, 인프라 반납 이후에도 로직 복구 및 유지보수가 가능한 환경을 구축하기 위함.

### 2.2.2 AWS 클라우드 환경

<img width="854" height="536" alt="cloud_pipeline" src="https://github.com/user-attachments/assets/a5eac6f3-5033-43f9-bcd5-659262be8fe3" />

**워크로드별 인스턴스 사이징 및 최적화**

- 컴퓨팅(EC2): 데이터 처리(Airflow)와 시각화(Streamlit) 각 서버의 안정적인 메모리 확보를 위해 모두 t3.medium 타입을 적용하여, 쿼리 처리 및 대시보드 렌더링 시의 병목 현상 방지.
- 데이터베이스(RDS): 프로젝트 규모와 데이터 마트(Data Mart)의 트랜잭션 빈도를 고려하여 db.t3.micro (Free Tier 급)를 선정, 성능 저하 없이 비용 효율성 극대화.

**보안 및 접근 제어 강화**

- 최소권한정책:  AWS Lambda가 인프라를 제어할 때 불필요한 권한을 갖지 않도록, 오직 대상 EC2/RDS의 `Start`액션만 허용하는 Custom Inline Policy를 생성하여 적용.
- 보안그룹 화이트리스팅
    
    EC2: 운영자 IP 및 내부 통신을 위한 포트(SSH 22, Web 8080/8501)만 제한적으로 허용.
    
    RDS: 외부 인터넷 접근(0.0.0.0/0)을 원천 차단하고, 오직 EC2 보안 그룹 ID로부터의 인바운드 트래픽만 허용하여 DB 보안성 확보.
    

#### 🔑 Key Point: Lambda를 통한 인스턴스 기동 자동화

> 💡 본 프로젝트 환경은 클라우드 자원 비용 최적화를 위해 특정 시간대에 인스턴스를 자동으로 정지하는 엄격한 자원 관리 정책 아래 운영되었기 때문에 이를 Lambda를 통해 인스턴스 기동 자동화를 시행.
>
> [상세내용: Lambda를 통한 인스턴스 기동 자동화](./상세내용/lambda_instance_automation.md)

#### 🔑 Key Point: Athena 쿼리 지연 문제로 인한 RDS 도입

> 💡 Athena 쿼리로 S3 데이터를 가져오는 경우와 OLTP DB인 PostgreSQL을 사용하였을 때의 데이터 조회 속도 비교를 통해 RDS 도입 진행.
>
> [상세내용: RDS 도입 배경 - Athena 쿼리 지연 문제](./상세내용/background_of_use_rds.md)

### 모니터링 | CloudWatch

<img width="1998" height="1242" alt="cloudwatch1" src="https://github.com/user-attachments/assets/380685ab-ac53-4d73-919b-fb23adbac10f" />
<img width="1440" height="576" alt="Image" src="https://github.com/user-attachments/assets/c93ad06a-a24e-45d4-9658-4dab248f2598" />

### 2.2.3 `.env` 환경변수를 활용한 Local ↔ AWS 커넥션 동적 제어

**배경 및 필요성**

- **환경별 커넥션 상이 :** 로컬 개발 환경과 AWS 운영 환경은 사용되는 쿼리 엔진, 스토리지, RDS 등 연결 정보가 서로 달라 별도의 커넥션 관리가 필수적임.
- **코드 변경 최소화의 필요성 :** 환경이 변경될 때마다 소스 코드 내 접속 정보를 직접 수정하는 방식은 운영 리스크를 높이고 자동화 및 배포 파이프라인 구성에 부적합함.

이에 따라 **코드 수정 없이 실행 환경에 따라 커넥션을 자동으로 전환**할 수 있는 구조가 필요함.

**구현 방안**

- **환경 식별자 정의**: `.env` 파일에 `AIRFLOW_ENV=aws` 또는 `AIRFLOW_ENV=local` 변수를 정의하여, Airflow 구동 시 컨테이너 내부로 환경 정보를 자동 주입함.
- **Connection Utility 개발**: `airflow/plugins/connection_utils.py` 모듈을 구축하여, 주입된 환경변수 값에 따라 적합한 스토리지(S3/MinIO), 쿼리 엔진(Athena/Trino) 및 RDS 커넥션 객체를 반환하는 **동적 분기 로직**을 구현함.
    <details>
    <summary>config 설정 예시</summary>
    <div markdown="1">

    ```json
    CONNECTION_CONFIG = {
        "aws": {
            "storage": "s3_conn",
            "query_engine": "athena_conn",
            "dbms": "rds_conn",
        },
        "local": {
            "storage": "minio_conn",
            "query_engine": "trino_conn",
            "dbms": None,  # 추후 업데이트 예정
        },
    }
    ```

    </div>
    </details>
        
- **인터페이스 단일화**: DAG 및 오퍼레이터는 상세 접속 정보에 의존하지 않고, 유틸리티 함수를 호출하여 현재 환경에 최적화된 연결 정보만을 주입받아 사용함.

## 2.3 데이터 파이프라인

### 2.3.1 수집 대상 데이터 상세

| API 정보 | API 내용 |
| --- | --- |
| [일별 부류별 도.소매가격정보](https://www.kamis.or.kr/customer/reference/openapi_list.do?action=detail&boardno=1) | 일별 부류별 도.소매가격정보 |
| [친환경농산물 품목별가격정보('20.4~)](https://www.kamis.or.kr/customer/reference/openapi_list.do?action=detail&boardno=13) | 친환경농산물 품목별가격정보 |
| [농축수산물 품목 및 등급 코드표](https://www.kamis.or.kr/customer/reference/openapi_list.do?action=detail&boardno=15) | 농축수산물 품목 및 등급 코드표 |
| [신)일별 품목별 소매 가격자료(기간설정가능, 최대1년)](https://www.kamis.or.kr/customer/reference/openapi_list.do?action=detail&boardno=17) | 일별 품목별 소매 가격자료 |
| [최근일자 지역별 도.소매가격정보(상품 기준)](https://www.kamis.or.kr/customer/reference/openapi_list.do?action=detail&boardno=10) | 최근일자 지역별 도.소매가격정보 |

### 2.3.2 데이터 파이프라인

#### 🔑 Key Point: 데이터 파이프라인 단계별 상세 정의

> 💡 농축수산물 가격 API 데이터를 기반으로, 수집 → 정제 → 분석 → 대시보드까지의 전 과정을 자동화하는 배치 처리 구조로 설계
> 

[상세내용: 데이터 파이프라인 단계별 상세 정의](./상세내용/details_of_data_pipelines.md)

<img width="1227" height="593" alt="Image" src="https://github.com/user-attachments/assets/aab70b68-bbde-4439-a0b8-15d6d9c92d95" />


> 💡 **DAG간 의존성 제어**
>
> - `TriggerDagRunOperator` 기반의 `Master Pipeline`라는 상위 오케스트레이션 DAG를 통해 전체 데이터 흐름을 통합적으로 제어하도록 설계
> - 이를 통해 사용자는 개별 수집·변환 DAG을 각각 스케줄링하여 실행할 필요 없이, Master DAG 하나만 실행함으로써 전체 데이터 흐름을 일관되게 관리
> - 파이프라인의 실행 순서와 데이터 정합성을 보장하면서도, 유지보수성과 확장성을 고려한 안정적인 배치 처리 구조를 구축

### 2.3.3 ERD

**Silver-Gold Layer**

<img width="2570" height="2705" alt="Image" src="https://github.com/user-attachments/assets/b1970748-bb7e-4d91-ae48-d1dcb14ea444" />

### **2.3.4 dbt Data Lineage**

> dbt Lineage를 활용하여 API 원천 데이터부터 목적별 데이터 마트(Mart)까지의 의존 관계를 가시화하고, 데이터 흐름의 투명성 및 변경 영향도 분석 능력 확보
> 

![dbt Data Lineage](https://github.com/user-attachments/assets/1ae12989-345a-4ae4-98ae-5554cdeb573a)

## 2.4 프로젝트 협업

### 2.4.1 역할

| 담당자 | 담당역할 | 상세업무 |
| --- | --- | --- |
| 구다혜 | 프로젝트 총괄(팀장) | - 프로젝트 일정 관리 <br> - ETL, ELT, 대시보드 구현<br>- 메타데이터 수집 및 정리 <br>- 최종 결과물 작성 |
| 정수진 | AWS 관리자 | - 클라우드 인프라 구축 및 관리<br>- Streamlit 환경 및 공통 레이아웃 구성<br> - 최종 결과물 작성 |
| 김지연 | GitHub 관리자 | - GitHub 구성 및 관리<br> - ETL, ELT, 대시보드 구현<br> - Streamlit 도커라이징 및 CI/CD 구현<br> - 최종 결과물 작성 |
| 박정은 | 로컬 환경 관리자 | - 로컬환경 구성<br> - 클라우드 변환 및 airflow CI/CD 구현<br>- ETL 및 ELT 로직 구현 <br>- 최종 결과물 작성 |

### 2.4.2 코드 품질 관리

- **dag 파일명 / 칼럼명 / 테이블명 네이밍 컨벤셩 정의**
    
    > 데이터 신뢰성과 협업 효율성 향상을 위해 표준화된 네이밍 규칙을 사전에 정의
    > 
    
    | **구분** | 설명 |
    | --- | --- |
    | dag 파일명 | - raw_api명_collect_주기.py <br>  - silver_api명_transform_주기.py   <br> - test_목적_키워드.py |
    | 칼럼명 | - 소문자 사용<br>    - 축약어 사용<br>    e.g. `~명` → `_nm` /  `~코드` → `_cd` |
    | 테이블명 | - stg_주기_키워드<br>    - mart_키워드 |
- **pre-commit : 자동화된 코드 검증 및 결함 차단**
    
    > 일관된 코드 포맷을 유지하고, 사소한 문법 에러가 원격 저장소 및 운영 환경(CD)으로 전파되는 것을 사전에 차단하여 배포 안정성 확보
    > 
    
    | Hook Name | 설명 |
    | --- | --- |
    | detect-private-key | 커밋 단계에서 보안에 민감한 키 정보가 포함된 파일을 감지하여 저장소 유입을 방지 |
    | check-merge-conflict | 병합 과정에서 발생한 충돌 표시가 제거되지 않은 채 커밋되는 상황을 사전에 차단 |
    | ruff | Python 코드에 대해 정적 분석을 수행하여 import 정렬, 미사용 코드 제거, 네이밍 규칙 및 복잡성 기준을 자동으로 검사하고 일부 항목은 자동 수정 |
    | ruff-format | Airflow 코드에 일관된 포맷 규칙을 적용하여 코드 스타일 편차를 최소화 |
- **Docstring 컨벤션 : 코드 가독성 및 문서화 표준화**
    
    > 모든 파이썬 파일에 **`Google` 스타일 `Docstring`** 컨벤션을 적용하여 
    함수와 클래스의 역할, 매개변수, 반환값에 대한 설명을 표준화 → **비즈니스 가시성 확보**
        

### **2.4.3 github flow**

> 브랜치를 하나의 `base(main)`을 두고 그에 대해 기능을 추가하기 위한 브랜치 `dev`를 분리하여 간단하고 빠르게 배포 수정할 수 있는 전략
> 

<img width="883" height="241" alt="Image" src="https://github.com/user-attachments/assets/0865da16-2212-4d52-80a9-2e36d55436b9" />

> 💡 **브랜치 전략이 단순한 만큼, 병합 전 품질 검증을 강화**
>
> - `pre-commit`: 코드 스타일, 정적 분석, 기본 검증을 로컬 단계에서 수행 + 일관성 유지
> - `CI/CD` 파이프라인: CI 통과 했을 시에 `main` 브랜치에 반영하여, CD 진행 가능

### 2.4.4 CI/CD

<div style="background-color: #e3f2fd; font:"> <strong>Airflow_dbt Repository</strong></div>


> **Self-hosted Runner** 기반의 CI/CD를 구축하여 dbt 모델 및 Airflow DAG 수정 사항이 운영 EC2 인스턴스에 즉각적이고 안전하게 반영되도록 파이프라인 관리 프로세스 고도화
> 

**CI (Continuous Integration)**

- `Push` 및 `PR` 생성 시 Ruff를 통한 코드 스타일 점검과 Airflow CLI 기반의 DAG 임포트 에러 검사를 자동화하여 운영 환경에 결함이 있는 코드가 배포되는 것을 원천 차단
- CI 환경 내에서 가벼운 SQLite를 활용한 DB 마이그레이션과 DAG 직렬화 검증을 선행하여 런타임 오류 가능성을 최소화
    

**CD (Continuous Deployment)**

- ‘Self-hosted Runner’ 기반의 `rsync`를 통한 코드 동기화, 환경 변수 로드, 서비스 재기동 및 헬스 체크까지의 전 과정을 자동화
- 배포 전 자동 백업 및 실패 시 즉각적인 롤백(Rollback) 메커니즘을 구축하여 서비스 가동 중단(Downtime) 위험을 최소화하였으며, 최근 3개의 백업본을 상시 유지하여 리소스 제약 환경에서도 안정적인 복구 가용성을 확보
- 배포 이력 로깅과 컨테이너 상태의 실시간 검증을 통해 t3.medium 인스턴스 내 파이프라인 운영의 안정성을 확보하고 모니터링 체계를 강화
    


<div style="background-color: #e3f2fd; font:"> <strong>Streamlit Repository</strong></div>

> GitHub Secrets 보안 인증과 Docker 기반의 빌드 프로세스를 연계하여, Streamlit 앱의 최신 소스 코드를 운영 환경에 실시간 이미지 업데이트 형식으로 배포하는 체계 구축
> 

**CI (Continuous Integration)**

- `Push` 이벤트 발생 시 **소스 코드 Checkout(Pull) 중심의 최소 CI 단계**로 구성

**CD (Continuous Deployment)**

- Docker 기반 빌드 및 EC2 배포 전 과정을 GitHub Actions로 자동화
- 이미지 빌드 → EC2 전송 → 컨테이너 재기동의 일관된 배포 흐름 구성
    

# 3. 프로젝트 결과

## 3.1 streamlit 대시보드

### 3.1.1 streamlit 구현 특징

**모듈화된 컴포넌트 구조**

> 각 컴포넌트는 명확한 책임을 가지도록 분리되어, 재사용성과 유지보수성을 고려한 대시보드 아키텍처를 구현
> 

**컴포넌트 분류**

- **페이지 컴포넌트**: 친환경 페이지(`eco_panel.py`), 유통업체 비교(`channel_cards.py`)
- **시각화 컴포넌트**: 가격 카드(`price_cards.py`), 가격 그래프(`price_graph.py`), 제철 카드(`season_cards.py`)
- **지도 컴포넌트**: 지역별 지도(`region_map.py`), 제철 지도(`season_map.py`)

**특징 및 장점**

- 컴포넌트 단위의 독립적인 개발·테스트 가능
- 메인 앱(`app.py`)에서는 컴포넌트 조합만 담당하여 구조 단순화

---

**데이터베이스 연결 및 쿼리 관리 추상화**

> Athena, RDS, Trino 등 서로 다른 특성을 가진 데이터 소스를 동일한 방식으로 처리하기 위해 데이터베이스 연결 추상화 계층을 설계하여 데이터 소스 변경 시 streamlit 컴포넌트 수정없이 대응하기에 용이하도록 구현.
> 

**구현 방식**

- **데이터베이스 연결 추상화**
    - `DatabaseConnection` Protocol을 통해 공통 인터페이스(`execute_query`, `get_config`) 정의
    - 팩토리 함수(`get_database_connection`)로 데이터베이스 타입에 따라 연결 객체 동적 생성
    - `RDSConnection`, `AthenaConnection`, `TrinoConnection`이 동일 인터페이스를 구현
        <details>
        <summary>config 설정 예시</summary>
        <div markdown="1">

        ```py
        class DatabaseConnection(Protocol):
            def execute_query(self, query: str, **kwargs) -> pd.DataFrame: ...
            def get_config(self) -> tuple[str, str]: ...
        
        # 팩토리 함수
        def get_database_connection(db_type: Literal["rds", "athena", "trino"]):
            if db_type == "rds":
                return RDSConnection()
            elif db_type == "athena":
                return AthenaConnection()
            elif db_type == "trino":
                return TrinoConnection()
        ```

        </div>
        </deatils>
        
- **쿼리 관리 분리**
    - `data/queries` 디렉터리에 기능별 SQL 모듈 구성
    - SQL 로직을 컴포넌트에서 완전히 분리하여 재사용성과 가독성 향상

### 3.1.2 결과 대시보드

- **오늘의 식재료 탭**

![오늘의 식재료 탭](https://github.com/user-attachments/assets/c2cf340e-0bcd-4507-b7ff-25dc697f1dea)

- **친환경 정보 탭**

![친환경 정보 탭](https://github.com/user-attachments/assets/3613c9dc-7275-446a-8870-3e94768430bd)

- **유통업체별 정보 탭**

![유통업체별 정보 탭](https://github.com/user-attachments/assets/43e0027f-f574-4a18-85e0-14742178a2d1)

## 3.2 트러블슈팅

### 🚨 t3.medium 환경에서의 Airflow 운영 안정화 및 리소스 최적화 전략

> 💡 EC2(t3.medium)의 자원 한계로 발생한 시스템 프리징의 원인을 커널 로그 분석으로 규명하고, Swap 메모리 확보 및 Airflow 환경 변수 최적화를 통해 서비스 안정성을 확보함.
>
> [상세내용: t3.medium 환경에서의 Airflow 운영 안정화 및 리소스 최적화 전략](../troubleshooting/t3_medium_ec2_airflow_resource.md)

### 🚨 DooD 환경의 Airflow-dbt 컨테이너 간 Docker 소켓 권한 장애

> 💡 로컬 환경과 다른 EC2(Ubuntu)의 엄격한 보안 정책으로 인해 발생한 Docker 소켓 권한 문제를 GID 매핑 시행착오를 거쳐 최적의 권한 조정(chmod 666)으로 해결.
>
> [상세내용: DooD 환경의 Airflow-dbt 컨테이너 간 Docker 소켓 권한 장애](../troubleshooting/dood_airflow_dbt_container_socket_chmod.md)

### 🚨 Parquet 내부 컬럼과 파티션 메타데이터 간 정합성 오류 해결

> 💡 Athena가 파티션 메타데이터를 우선시하면서 발생한 컬럼 충돌 문제를 해결하기 위해 Silver 테이블을 파티션 기반 구조로 재정의하였으며, 이를 통해 오류를 제거하고 성능 최적화와 유지보수 용이성을 동시에 확보하고자 함.
>
> [상세내용: Parquet 내부 컬럼과 파티션 메타데이터 간 정합성 오류 해결](../troubleshooting/parquet_columns_partition_metadata_error.md)

### 🚨 Athena 워크그룹 설정 충돌에 따른 dbt 모델 S3 저장 경로(location) 미적용 문제

> 💡 dbt 모델에서 지정한 S3 저장 경로가 무시되는 현상을 분석하여, 실제 쿼리 작업을 수행하는 Athena 워크그룹의 '설정 재정의' 옵션이 원인임을 식별하고 이를 비활성화하여 코드 기반의 저장 위치 제어권을 정상화함.
>
> [상세내용: Athena 워크그룹 설정 충돌에 따른 dbt 모델 S3 저장 경로(location) 미적용 문제](../troubleshooting/athena_work_group_conflict_in_dbt_s3_location.md)

## 3.3 성과

- **데이터 파이프라인 설계 역량 및 클라우드 이관 안정성 확보**
    - **로직 선제 검증:** 로컬 환경(Docker, MinIO)에서 ETL/ELT 로직의 기술적 타당성을 사전에 검토하여 클라우드 이관 시 리스크 최소화
    - **연속성 있는 운영:** 검증된 로직을 AWS 환경으로 확장하고 Apache Airflow를 통한 오케스트레이션 체계를 구축하여 데이터 파이프라인의 운영 안정성 확보
- **협업 효율화를 위한 코드 품질 및 운영 관리 체계 정립**
    - **표준화된 개발 환경:** **Ruff 및 Pre-commit** 도입으로 코드 스타일을 규격화하고, **GitHub Docstring 표준** 준수를 통한 프로젝트 유지보수성 향상
    - **자동화 프로세스 경험:** **GitHub Actions 기반의 CI/CD** 파이프라인을 직접 구축하여 코드 테스트 및 배포 전 과정의 자동화 운영 경험 축적
- **데이터 기반의 의사결정 지원 체계 구현**
    - **데이터 가독성 최적화:** dbt를 활용해 파편화된 데이터를 분석용 마트로 재구성하고, **Streamlit** 대시보드를 통해 시각화 효율 향상
    - **실무적 솔루션 제시:** 다양한 물가 정보 기반의 합리적 소비 가이드를 제공함으로써, 고물가 시대 소비자의 정보 탐색 비용 절감 및 의사결정 편의성 증대

## 3.4 한계점 및 향후 개선사항

- **컨테이너 오케스트레이션 도입 및 네트워크 보안 아키텍처 고도화(클라우드 아키텍처 관점)**
    - **한계점:** 현재 단일 EC2 인스턴스 기반의 아키텍처는 트래픽 급증 시 유연한 수평적 확장(Scale-out)에 구조적 한계가 존재함. 또한 편의성을 위해 구성된 Public Subnet 중심의 네트워크 환경은 데이터베이스 및 내부 로직이 외부 위협에 노출될 수 있는 잠재적 보안 취약점을 가짐.
    - **개선 방향:** **AWS ECS(Fargate)** 기반의 서버리스 컨테이너 환경으로 전환하여 인프라 관리 오버헤드를 제거하고 부하에 따른 자동 확장(Auto-scaling) 체계 확보. 아울러 리소스를 **Private Subnet**으로 격리하고 NAT Gateway 및 Bastion Host를 통한 접근 제어 정책을 도입하여 엔터프라이즈 수준의 보안 아키텍처 완성.
- **리소스 제약에 따른 성능 병목 및 실시간 모니터링 체계 고도화(시스템 엔지니어링 관점)**
    - **한계점:** **EC2 t3.medium**의 제한적인 자원 환경에서 Airflow 운용함에 따라 간헐적인 리소스 경합 및 스케줄링 지연 발생. **AWS CloudWatch**의 기초 메트릭만으로는 API 수집 단계의 세부 로직 장애나 프로세스 중단을 즉각적으로 감지하는 데 한계가 있음.
    - **개선 방향:** 인프라 사양 확장(Scale-up)과 더불어 **Prometheus & Grafana**를 연동하여 어플리케이션 레벨의 메트릭을 가시화하고, 장애 발생 시 즉각 대응이 가능한 **Slack 알림 체계의 정교화** 추진.
- **데이터 적시성 보장을 위한 SLA 기반 관리 및 알람 체계 정립(데이터 엔지니어링 관점)**
    - **한계점:** 데이터 공급의 최소 품질 기준인 **SLA(Service Level Agreement)** 지표가 부재하여, 수집 실패나 처리 지연 발생 시 운영자가 실시간으로 인지할 수 있는 능동적 감시 체계가 미흡함. 이로 인해 데이터 최신성(Data Freshness)에 문제가 생길 경우 서비스 신뢰도 저하 가능성 존재.
    - **개선 방향:** 파이프라인 단계별 **SLA 가용성 지표**를 설정하고, **Airflow SLA Miss 및 Callback** 기능을 활용해 임계치 초과 시 즉시 장애 전파 및 자동 복구 시나리오가 실행되는 안정적 운영 기반 구축.
- **데이터 수집 채널 다변화 및 커버리지 확대**
    - **한계점:** 현재 공공 API 기반의 데이터 소스에 주로 의존하고 있어, 대형 마트나 온라인 커머스 등 소비자가 체감하는 민간 유통 채널의 실시간 할인 정보 및 품절 현황을 즉각적으로 반영하는 데 한계가 있음.
    - **개선 방향:** 크롤링 파이프라인을 추가 구축하여 데이터 소스를 다각화하고, 수집 품목과 지역 범위를 전국 단위로 확장하여 데이터의 현실성 및 포괄성 향상.
